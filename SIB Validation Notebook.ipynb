{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d26616",
   "metadata": {},
   "source": [
    "### 1) Import the Relevant Files & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3492a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sib_main.sib_sub.sib_validation_main as svm\n",
    "import sib_main.sib_sub.sib_validation_imports as svi\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "from shapely.geometry.multipoint import MultiPoint\n",
    "from shapely.ops import nearest_points\n",
    "from datetime import datetime\n",
    "\n",
    "ground_truth = gpd.read_file(\"E:/SIB/package/data/model3a_GoodPasture/inputs/ground_truth/GT.shp\")\n",
    "model_det = gpd.read_file(\"E:/SIB/package/data/model3a_GoodPasture/inputs/detected_points/det.shp\")\n",
    "VHRsamples = gpd.read_file(\"E:/SIB/package/data/model3a_GoodPasture/inputs/vhr_samples/VHRValidation_samples.shp\")\n",
    "\n",
    "export_path = \"E:/SIB/package/data/model3a_GoodPasture/outputs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046bc0eb",
   "metadata": {},
   "source": [
    "### 2) Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab86c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0% of values above = 0.2104917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2104917"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svi.confidence_filter(model_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800e9cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function multi_to_single in module sib_main.sib_sub.sib_validation_imports:\n",
      "\n",
      "multi_to_single(gdf)\n",
      "    This function creates POINT geometries from MULTIPOINT geometries.\n",
      "    It does so by simply creating a centroid for each point and returning the gdf at the end.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svi.multi_to_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651590f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'geometry' column from 'MULTIPOINT' to 'POINT'\n",
    "ground_truth = svi.multi_to_single(ground_truth)\n",
    "model_det = svi.multi_to_single(model_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b87ba8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function preprocessing in module sib_main.sib_sub.sib_validation_main:\n",
      "\n",
      "preprocessing(ground_truth_points, model_detected_points, conf_percentile=10)\n",
      "    Preprocesses the data to a certain format:\n",
      "    a) checks geometry type\n",
      "    b) filters the confidence values by a chosen percentile\n",
      "    c) verifies the correct crs\n",
      "    d) establishes a unique ID for each GeoDataFrame\n",
      "    e) renames the relevant columns to a standard format\n",
      "    f) drops any unrelated columns and attributes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm.preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179ff04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted Geometries: 'POINT'\n",
      "Accepted Geometries: 'POINT'\n",
      "90.0% of values above = 0.2104917\n"
     ]
    }
   ],
   "source": [
    "ground_truth, model_det = svm.preprocessing(ground_truth, model_det, conf_percentile=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2caa746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ground Truth Points: 2151\n",
      "Number of Model Detected Points: 2037\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Ground Truth Points: {}\".format(len(ground_truth)))\n",
    "print(\"Number of Model Detected Points: {}\".format(len(model_det)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804183a8",
   "metadata": {},
   "source": [
    "### 3) Find the maximum value of detected points within a 2m radius of a ground truth point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faffe50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ = svi.n_max(ground_truth, model_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd6b6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ffe2e",
   "metadata": {},
   "source": [
    "### 4) Run the body of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3dc406e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE NEGATIVES GEODATAFRAME CONSTRUCTED\n",
      "\n",
      "Initial True Positives, Count: 1948\n",
      "Initial False Positives, Count: 117\n",
      "Length of 'model_det' after TP rows dropped: 255\n",
      "\n",
      "Length of 'model_det' after FP rows dropped: 160\n",
      "\n",
      "Length of 'Ground Truth points' after TP rows dropped: 203\n",
      "\n",
      "Initial True Positives, Count: 23\n",
      "There were no incorrect classifications (FP1) detected on this pass.\n",
      "Length of 'model_det' after TP rows dropped: 152\n",
      "\n",
      "Length of 'model_det' after FP rows dropped: 152\n",
      "\n",
      "Length of 'Ground Truth points' after TP rows dropped: 180\n",
      "\n",
      "Initial True Positives, Count: 0\n",
      "There were no incorrect classifications (FP1) detected on this pass.\n",
      "Length of 'model_det' after TP rows dropped: 152\n",
      "\n",
      "Length of 'model_det' after FP rows dropped: 152\n",
      "\n",
      "Length of 'Ground Truth points' after TP rows dropped: 180\n",
      "\n",
      "Initial True Positives, Count: 0\n",
      "There were no incorrect classifications (FP1) detected on this pass.\n",
      "Length of 'model_det' after TP rows dropped: 152\n",
      "\n",
      "Length of 'model_det' after FP rows dropped: 152\n",
      "\n",
      "Length of 'Ground Truth points' after TP rows dropped: 180\n",
      "\n",
      "TRUE POSITIVEs GEODATAFRAME CONSTRUCTED\n",
      "\n",
      "FALSE POSITIVES GEODATAFRAME CONSTRUCTED\n",
      "\n",
      "FALSE NEGATIVES GEODATAFRAME CONSTRUCTED\n",
      "\n",
      "VHRVALIDATION GEODATAFRAME CONSTRUCTED\n",
      "0:06:29.703837\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "global_tp = []\n",
    "global_fp = []\n",
    "\n",
    "global_fn_df = svm.calculate_fn(ground_truth, model_det)\n",
    "print(\"FALSE NEGATIVES GEODATAFRAME CONSTRUCTED\\n\")\n",
    "\n",
    "for i in range(0, n_):\n",
    "\n",
    "    # 1) CALCULATE NEAREST\n",
    "    nearest_neighbour = svm.call_calculate_nearest(ground_truth, model_det)\n",
    "    \n",
    "    # 2) CALCUALTE DISTANCE\n",
    "    nearest_neighbour = svm.calculate_distance(nearest_neighbour)\n",
    "    \n",
    "    # 3) CALCULATE TP\n",
    "    nearest_neighbour, tp, tp_previous_pass = svm.calculate_tp(nearest_neighbour)\n",
    "    tp_dict = tp.to_dict('list')\n",
    "    try:\n",
    "        global_tp.append(tp_dict)\n",
    "    except AttributeError:\n",
    "        print(\"No more True Positives to append\")\n",
    "        pass\n",
    " \n",
    "    # 4) CALCULATE FP\n",
    "    nearest_neighbour, fp = svm.calculate_fp(nearest_neighbour)\n",
    "    fp_dict = fp.to_dict('list')\n",
    "    try:\n",
    "        global_fp.append(fp_dict)\n",
    "    except AttributeError:\n",
    "        print(\"No more False Positives to append\")\n",
    "        pass\n",
    "         \n",
    "    # 5) DROP INDICES\n",
    "        # DROP TP INDICES\n",
    "    model_det = svi.drop_indices(model_det, tp, outcome_value='true')\n",
    "    \n",
    "        # DROP FP INDICES\n",
    "    model_det = svi.drop_indices(model_det, fp, outcome_value='false')\n",
    "    \n",
    "        # DROP GROUND TRUTH INDICES\n",
    "    ground_truth = svi.drop_indices(ground_truth, tp, outcome_value='ground')\n",
    "    \n",
    "# 6) CREATE GEODATAFRAMES FOR TRUE POSITIVES AND FALSE POSITIVES\n",
    "global_tp_df = svi.create_global_GeoDataFrame(global_tp)\n",
    "global_fp_df = svi.create_global_GeoDataFrame(global_fp)\n",
    "print(\"TRUE POSITIVEs GEODATAFRAME CONSTRUCTED\\n\")\n",
    "\n",
    "# 7) CONSTRUCT THE COMPLETE FALSE POSITIVES DATAFRAME\n",
    "fp2 = svi.extract_points_outside_2m(ground_truth, model_det)\n",
    "global_fp_df = global_fp_df.append(fp2)\n",
    "print(\"FALSE POSITIVES GEODATAFRAME CONSTRUCTED\\n\")\n",
    "\n",
    "# 7) CALCULATE FN\n",
    "global_fn_df = svm.calculate_fn(ground_truth, model_det)\n",
    "print(\"FALSE NEGATIVES GEODATAFRAME CONSTRUCTED\\n\")\n",
    "\n",
    "# 8) CREATE_VALIDATION_DATAFRAME\n",
    "VHRsamples = svm.create_validation_dataframe(VHRsamples, global_tp_df, global_fp_df, global_fn_df)\n",
    "print(\"VHRVALIDATION GEODATAFRAME CONSTRUCTED\")\n",
    "\n",
    "\"\"\"# 9) EXPORT GEODATAFRAME\n",
    "svm.export_GeoDataFrame(export_path, VHRsamples, file_name='VHRSamples', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_tp_df, file_name='TP', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_fp_df, file_name='FP', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_fn_df, file_name='FN', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, ground_truth, file_name='ground_truth_OUTPUT', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, model_det, file_name='model_det_OUTPUT', extension='.shp')\"\"\"\n",
    "\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fe7288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to Local Drive\n",
      "Exported to Local Drive\n",
      "Exported to Local Drive\n",
      "Exported to Local Drive\n",
      "Exported to Local Drive\n",
      "Exported to Local Drive\n"
     ]
    }
   ],
   "source": [
    "svm.export_GeoDataFrame(export_path, VHRsamples, file_name='VHRSamples', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_tp_df, file_name='TP', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_fp_df, file_name='FP', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, global_fn_df, file_name='FN', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, ground_truth, file_name='ground_truth_OUTPUT', extension='.shp')\n",
    "svm.export_GeoDataFrame(export_path, model_det, file_name='model_det_OUTPUT', extension='.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5b6099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
